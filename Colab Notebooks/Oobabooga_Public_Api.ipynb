{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFQl6-FjSYtY"
      },
      "source": [
        "# LLM text generation notebook for Google Colab\n",
        "\n",
        "This notebook uses [https://github.com/oobabooga/text-generation-webui](https://github.com/oobabooga/text-generation-webui) to run conversational models in chat mode.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Credits\n",
        "\n",
        "Based on the [original notebook by 81300](https://colab.research.google.com/github/81300/AI-Notebooks/blob/main/Colab-TextGen-GPU.ipynb).\n",
        "\n",
        "Forked from [Philio](https://github.com/pcrii/Philo-Colab-Collection/blob/main/4bit_TextGen_Gdrive.ipynb).\n",
        "\n",
        "Find the base Colab notebook used to create this one [here](https://github.com/eucdee/AI)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aetherius Ai Assistant\n",
        "\n",
        "Aetherius Ai Assitant is an Ai personal assistant/companion that can be ran using the Oobabooga Api.  I have set up this collab notebook so those without a GPU can use it.\n",
        "The main Aetherius Program Should be ran on your main computer.\n",
        "\n",
        "To connect to the google colab notebook, edit the Host Url located in Aetherius's Config Menu.  Replace \"http://localhost:5000/api\" with the given Non-Streaming Public URL from this Google Colab.  Leave in the /api.\n",
        "\n",
        "*Remember to change the runtime type to use GPU under the \"Runtime\" tab*\n",
        "\n",
        "## Github:\n",
        "https://github.com/libraryofcelsus/Aetherius_AI_Assistant"
      ],
      "metadata": {
        "id": "c92q9hRC92tk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7TVVj_z4flw"
      },
      "outputs": [],
      "source": [
        "#@title Keep this tab alive to prevent Colab from disconnecting you { display-mode: \"form\" }\n",
        "\n",
        "#@markdown Press play on the music player that will appear below:\n",
        "%%html\n",
        "<audio src=\"https://oobabooga.github.io/silence.m4a\" controls>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGQ8BiMuXMDG",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Install the web UI\n",
        "#remember gradio is currently held back\n",
        "save_logs_to_google_drive = False #@param {type:\"boolean\"}\n",
        "save_everything_to_google_drive = False #@param {type:\"boolean\"}\n",
        "#@markdown remember these models are large and free Gdrive is only 15Ggb <br>\n",
        "install_gptq = True #@param {type:\"boolean\"}\n",
        "from IPython.display import clear_output\n",
        "if save_logs_to_google_drive:\n",
        "  import os\n",
        "  import shutil\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  base_folder = '/content/drive/MyDrive'\n",
        "\n",
        "if save_everything_to_google_drive:\n",
        "    import os\n",
        "    import shutil\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    base_folder = '/content/drive/MyDrive'\n",
        "    repo_dir = '/content/drive/MyDrive/text-generation-webui'\n",
        "    model_dir = '/content/drive/MyDrive/text-generation-webui/models'\n",
        "    gptq_dir = '/content/drive/MyDrive/text-generation-webui/repositories/GPTQ-for-LLaMa'\n",
        "    if os.path.exists(repo_dir):\n",
        "        %cd {repo_dir}\n",
        "        !git pull\n",
        "    else:\n",
        "        %cd /content/drive/MyDrive/\n",
        "        !git clone https://github.com/oobabooga/text-generation-webui\n",
        "\n",
        "else:\n",
        "    model_dir = '/content/text-generation-webui/models'\n",
        "    repo_dir = '/content/text-generation-webui'\n",
        "    %cd /content\n",
        "    !git clone https://github.com/oobabooga/text-generation-webui\n",
        "\n",
        "\n",
        "\n",
        "if save_logs_to_google_drive:\n",
        "  if not os.path.exists(f\"{base_folder}/oobabooga-data\"):\n",
        "    os.mkdir(f\"{base_folder}/oobabooga-data\")\n",
        "  if not os.path.exists(f\"{base_folder}/oobabooga-data/logs\"):\n",
        "    os.mkdir(f\"{base_folder}/oobabooga-data/logs\")\n",
        "  if not os.path.exists(f\"{base_folder}/oobabooga-data/softprompts\"):\n",
        "    os.mkdir(f\"{base_folder}/oobabooga-data/softprompts\")\n",
        "  if not os.path.exists(f\"{base_folder}/oobabooga-data/characters\"):\n",
        "    shutil.move(\"text-generation-webui/characters\", f\"{base_folder}/oobabooga-data/characters\")\n",
        "  else:\n",
        "    !rm -r \"text-generation-webui/characters\"\n",
        "\n",
        "  !rm -r \"text-generation-webui/softprompts\"\n",
        "  !ln -s \"$base_folder/oobabooga-data/logs\" \"text-generation-webui/logs\"\n",
        "  !ln -s \"$base_folder/oobabooga-data/softprompts\" \"text-generation-webui/softprompts\"\n",
        "  !ln -s \"$base_folder/oobabooga-data/characters\" \"text-generation-webui/characters\"\n",
        "\n",
        "else:\n",
        "  !mkdir text-generation-webui/logs\n",
        "\n",
        "!ln -s text-generation-webui/logs .\n",
        "!ln -s text-generation-webui/characters .\n",
        "!ln -s text-generation-webui/models .\n",
        "%rm -r sample_data\n",
        "%cd text-generation-webui\n",
        "!wget https://raw.githubusercontent.com/pcrii/Philo-Colab-Collection/main/settings-colab-template.json -O settings-colab-template.json\n",
        "\n",
        "# Install requirements\n",
        "!pip install -r requirements.txt\n",
        "!pip install flask_cloudflared\n",
        "!pip install -r extensions/google_translate/requirements.txt\n",
        "!pip install -r extensions/silero_tts/requirements.txt\n",
        "print(f\"\\033[1;32;1m\\n --> If you see a warning about \\\"pydevd_plugins\\\", just ignore it and move on to Step 3. There is no need to restart the runtime.\\n\\033[0;37;0m\")\n",
        "\n",
        "if install_gptq:\n",
        "    if save_everything_to_google_drive:\n",
        "        if os.path.exists(gptq_dir):\n",
        "            %cd {gptq_dir}\n",
        "            !git pull\n",
        "            !pip install ninja\n",
        "            !pip install -r requirements.txt\n",
        "            !python setup_cuda.py install\n",
        "\n",
        "        else:\n",
        "            !mkdir /content/drive/MyDrive/text-generation-webui/repositories\n",
        "            %cd /content/drive/MyDrive/text-generation-webui/repositories\n",
        "            !git clone https://github.com/qwopqwop200/GPTQ-for-LLaMa\n",
        "            !ln -s GPTQ-for-LLaMa text-generation-webui/repositories/GPTQ-for-LLaMa\n",
        "            %cd GPTQ-for-LLaMa\n",
        "            !pip install ninja\n",
        "            !pip install -r requirements.txt\n",
        "            !python setup_cuda.py install\n",
        "    else:\n",
        "        %mkdir /content/text-generation-webui/repositories/\n",
        "        %cd /content/text-generation-webui/repositories/\n",
        "        !git clone https://github.com/qwopqwop200/GPTQ-for-LLaMa\n",
        "        !mkdir -p text-generation-webui/repositories\n",
        "        !ln -s GPTQ-for-LLaMa text-generation-webui/repositories/GPTQ-for-LLaMa\n",
        "        %cd GPTQ-for-LLaMa\n",
        "        !pip install ninja\n",
        "        !pip install -r requirements.txt\n",
        "        !python setup_cuda.py install\n",
        "!pip install --upgrade accelerate\n",
        "clear_output()\n",
        "print(\"Finished\")\n",
        "if save_logs_to_google_drive or save_everything_to_google_drive:\n",
        "    drive_NOT_mounted = False\n",
        "else:\n",
        "    drive_NOT_mounted = True\n",
        "\n",
        "if drive_NOT_mounted:\n",
        "  import os\n",
        "print(\"Available Models\")\n",
        "print(os.listdir(model_dir))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E7t4QfXf4U9p",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Download Model (Aetherius uses Llama-2-Chat)\n",
        "#@markdown you can insert any huggingface model in Organization/model format\n",
        "model_download = \"TheBloke/Llama-2-13B-chat-GPTQ\" # @param [\"TheBloke/Llama-2-13B-chat-GPTQ\", \"TheBloke/Llama-2-70B-chat-GPTQ\"] {allow-input: true}\n",
        "#@markdown  Download the model\n",
        "%cd {repo_dir}\n",
        "!python download-model.py {model_download}\n",
        "#this lists directorys from your model folder you can copy the name provided for the model you want for use in the the next cell\n",
        "!rm {model_dir}/place-your-models-here.txt\n",
        "clear_output()\n",
        "if save_logs_to_google_drive or save_everything_to_google_drive:\n",
        "    drive_NOT_mounted = False\n",
        "else:\n",
        "    drive_NOT_mounted = True\n",
        "\n",
        "if drive_NOT_mounted:\n",
        "  import os\n",
        "print(\"Available Models\")\n",
        "print(os.listdir(model_dir))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "m63OjWxwHY4N"
      },
      "outputs": [],
      "source": [
        "#@title Launch\n",
        "#@markdown Cloudflared may give some errors, as long as you get a non-streaming url, everything should work fine.  If no url is given, re-run this cell.\n",
        "import json\n",
        "\n",
        "model_load = \"TheBloke/Llama-2-13B-chat-GPTQ\" #@param {type:\"string\"}\n",
        "path_model_load = model_load.replace(\"/\", \"_\")\n",
        "# Parameters\n",
        "#auto_devices = False #@param {type:\"boolean\"}\n",
        "load_4bit_models = True #@param {type:\"boolean\"}\n",
        "\n",
        "groupsize_128 = True #@param {type:\"boolean\"}\n",
        "load_in_8bit = False #@param {type:\"boolean\"}\n",
        "api = True #@param {type:\"boolean\"}\n",
        "public_api = True #@param {type:\"boolean\"}\n",
        "\n",
        "Llama2_Seq_Length = True #@param {type:\"boolean\"}\n",
        "collab_free_tier = True #@param {type:\"boolean\"}\n",
        "collab_V_100 = False #@param {type:\"boolean\"}\n",
        "collab_A_100 = False #@param {type:\"boolean\"}\n",
        "\n",
        "text_streaming = True #@param {type:\"boolean\"}\n",
        "activate_silero_text_to_speech = False #@param {type:\"boolean\"}\n",
        "activate_sending_pictures = False #@param {type:\"boolean\"}\n",
        "activate_character_bias = False #@param {type:\"boolean\"}\n",
        "chat_language = \"English\" # @param ['Afrikaans', 'Albanian', 'Amharic', 'Arabic', 'Armenian', 'Azerbaijani', 'Basque', 'Belarusian', 'Bengali', 'Bosnian', 'Bulgarian', 'Catalan', 'Cebuano', 'Chinese (Simplified)', 'Chinese (Traditional)', 'Corsican', 'Croatian', 'Czech', 'Danish', 'Dutch', 'English', 'Esperanto', 'Estonian', 'Finnish', 'French', 'Frisian', 'Galician', 'Georgian', 'German', 'Greek', 'Gujarati', 'Haitian Creole', 'Hausa', 'Hawaiian', 'Hebrew', 'Hindi', 'Hmong', 'Hungarian', 'Icelandic', 'Igbo', 'Indonesian', 'Irish', 'Italian', 'Japanese', 'Javanese', 'Kannada', 'Kazakh', 'Khmer', 'Korean', 'Kurdish', 'Kyrgyz', 'Lao', 'Latin', 'Latvian', 'Lithuanian', 'Luxembourgish', 'Macedonian', 'Malagasy', 'Malay', 'Malayalam', 'Maltese', 'Maori', 'Marathi', 'Mongolian', 'Myanmar (Burmese)', 'Nepali', 'Norwegian', 'Nyanja (Chichewa)', 'Pashto', 'Persian', 'Polish', 'Portuguese (Portugal, Brazil)', 'Punjabi', 'Romanian', 'Russian', 'Samoan', 'Scots Gaelic', 'Serbian', 'Sesotho', 'Shona', 'Sindhi', 'Sinhala (Sinhalese)', 'Slovak', 'Slovenian', 'Somali', 'Spanish', 'Sundanese', 'Swahili', 'Swedish', 'Tagalog (Filipino)', 'Tajik', 'Tamil', 'Telugu', 'Thai', 'Turkish', 'Ukrainian', 'Urdu', 'Uzbek', 'Vietnamese', 'Welsh', 'Xhosa', 'Yiddish', 'Yoruba', 'Zulu']\n",
        "\n",
        "\n",
        "activate_google_translate = (chat_language != \"English\")\n",
        "\n",
        "language_codes = {'Afrikaans': 'af', 'Albanian': 'sq', 'Amharic': 'am', 'Arabic': 'ar', 'Armenian': 'hy', 'Azerbaijani': 'az', 'Basque': 'eu', 'Belarusian': 'be', 'Bengali': 'bn', 'Bosnian': 'bs', 'Bulgarian': 'bg', 'Catalan': 'ca', 'Cebuano': 'ceb', 'Chinese (Simplified)': 'zh-CN', 'Chinese (Traditional)': 'zh-TW', 'Corsican': 'co', 'Croatian': 'hr', 'Czech': 'cs', 'Danish': 'da', 'Dutch': 'nl', 'English': 'en', 'Esperanto': 'eo', 'Estonian': 'et', 'Finnish': 'fi', 'French': 'fr', 'Frisian': 'fy', 'Galician': 'gl', 'Georgian': 'ka', 'German': 'de', 'Greek': 'el', 'Gujarati': 'gu', 'Haitian Creole': 'ht', 'Hausa': 'ha', 'Hawaiian': 'haw', 'Hebrew': 'iw', 'Hindi': 'hi', 'Hmong': 'hmn', 'Hungarian': 'hu', 'Icelandic': 'is', 'Igbo': 'ig', 'Indonesian': 'id', 'Irish': 'ga', 'Italian': 'it', 'Japanese': 'ja', 'Javanese': 'jw', 'Kannada': 'kn', 'Kazakh': 'kk', 'Khmer': 'km', 'Korean': 'ko', 'Kurdish': 'ku', 'Kyrgyz': 'ky', 'Lao': 'lo', 'Latin': 'la', 'Latvian': 'lv', 'Lithuanian': 'lt', 'Luxembourgish': 'lb', 'Macedonian': 'mk', 'Malagasy': 'mg', 'Malay': 'ms', 'Malayalam': 'ml', 'Maltese': 'mt', 'Maori': 'mi', 'Marathi': 'mr', 'Mongolian': 'mn', 'Myanmar (Burmese)': 'my', 'Nepali': 'ne', 'Norwegian': 'no', 'Nyanja (Chichewa)': 'ny', 'Pashto': 'ps', 'Persian': 'fa', 'Polish': 'pl', 'Portuguese (Portugal, Brazil)': 'pt', 'Punjabi': 'pa', 'Romanian': 'ro', 'Russian': 'ru', 'Samoan': 'sm', 'Scots Gaelic': 'gd', 'Serbian': 'sr', 'Sesotho': 'st', 'Shona': 'sn', 'Sindhi': 'sd', 'Sinhala (Sinhalese)': 'si', 'Slovak': 'sk', 'Slovenian': 'sl', 'Somali': 'so', 'Spanish': 'es', 'Sundanese': 'su', 'Swahili': 'sw', 'Swedish': 'sv', 'Tagalog (Filipino)': 'tl', 'Tajik': 'tg', 'Tamil': 'ta', 'Telugu': 'te', 'Thai': 'th', 'Turkish': 'tr', 'Ukrainian': 'uk', 'Urdu': 'ur', 'Uzbek': 'uz', 'Vietnamese': 'vi', 'Welsh': 'cy', 'Xhosa': 'xh', 'Yiddish': 'yi', 'Yoruba': 'yo', 'Zulu': 'zu'}\n",
        "\n",
        "\n",
        "%cd {repo_dir}\n",
        "# Applying the selected language and setting the prompt size to 2048\n",
        "# if 8bit mode is selected\n",
        "\n",
        "\n",
        "\n",
        "params = set()\n",
        "if api:\n",
        "  params.add('--api')\n",
        "\n",
        "if collab_free_tier:\n",
        "  params.add('--gpu-split 14')\n",
        "\n",
        "if collab_V_100:\n",
        "  params.add('--gpu-split 15.5')\n",
        "\n",
        "if collab_A_100:\n",
        "  params.add('--gpu-split 39.5')\n",
        "\n",
        "if Llama2_Seq_Length:\n",
        "  params.add('--max_seq_len 4096')\n",
        "\n",
        "if public_api:\n",
        "  params.add('--public-api')\n",
        "\n",
        "if load_in_8bit:\n",
        "  params.add('--load-in-8bit')\n",
        "#if auto_devices:\n",
        "#  params.add('--auto-devices')\n",
        "if load_4bit_models:\n",
        "  params.add('--wbits 4')\n",
        "\n",
        "if groupsize_128:\n",
        "  params.add('--groupsize 128')\n",
        "\n",
        "active_extensions = []\n",
        "if activate_sending_pictures:\n",
        "  active_extensions.append('send_pictures')\n",
        "if activate_character_bias:\n",
        "  active_extensions.append('character_bias')\n",
        "if activate_google_translate:\n",
        "  active_extensions.append('google_translate')\n",
        "if activate_silero_text_to_speech:\n",
        "  active_extensions.append('silero_tts')\n",
        "active_extensions.append('gallery')\n",
        "\n",
        "if len(active_extensions) > 0:\n",
        "  params.add(f'--extensions {\" \".join(active_extensions)}')\n",
        "\n",
        "if not text_streaming or activate_google_translate or activate_silero_text_to_speech:\n",
        "  params.add('--no-stream')\n",
        "if activate_character_bias:\n",
        "  params.add('--verbose')\n",
        "\n",
        "# Starting the web UI\n",
        "cmd = f\"python server.py --share --model-dir {model_dir} --model {path_model_load} --model_type LLaMa --loader exllama {' '.join(params)}\"\n",
        "print(cmd)\n",
        "!$cmd"
      ]
    }
  ]
}